{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from opengrid.library import houseprint, caching, regression\n",
    "from opengrid import config\n",
    "\n",
    "c = config.Config()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create houseprint from saved file, if not available, parse the google spreadsheet\n",
    "try:\n",
    "    hp_filename = os.path.join(c.get('data', 'folder'), 'hp_anonymous.pkl')\n",
    "    hp = houseprint.load_houseprint_from_file(hp_filename)\n",
    "    print(\"Houseprint loaded from {}\".format(hp_filename))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Because of this error we try to build the houseprint from source\")\n",
    "    hp = houseprint.Houseprint()\n",
    "hp.init_tmpo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.sync_tmpos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use daily gas, electricity and water consumption data and weather data. Because we don't want to overload the weather API, we will only use 1 location (Ukkel).\n",
    "\n",
    "First, let's define the start and end date of the identification data.  That is the data to be used to find the model.  Later, we will use the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.Timestamp('2015-01-01', tz='Europe/Brussels')\n",
    "end = pd.Timestamp('now', tz='Europe/Brussels')\n",
    "end_model = pd.Timestamp('2016-12-31', tz='Europe/Brussels') #last day of the data period for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy data\n",
    "\n",
    "We for each consumption type (electricity, gas and water), we create a daily dataframe and save it in the dictionary dfs.  The data is obtained from the daily caches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caches = {}\n",
    "dfs = {}\n",
    "for cons in ['electricity', 'gas', 'water']:\n",
    "    caches[cons] = caching.Cache(variable='{}_daily_total'.format(cons))\n",
    "    dfs[cons] = caches[cons].get(sensors = hp.get_sensors(sensortype=cons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather and other exogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this block to download the weather data and save it to a pickle. This is a large request, and you can only do 2 or 3 of these per day before your credit with Forecast.io runs out!\n",
    "\n",
    "We also add a column for each day-of-week which may be used by the regression algorithm on a daily basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opengrid.library import forecastwrapper\n",
    "weather = forecastwrapper.Weather(location=(50.8024, 4.3407), start=start, end=end - pd.Timedelta(days=1))\n",
    "irradiances=[\n",
    "    (0, 90), # north vertical\n",
    "    (90, 90), # east vertical\n",
    "    (180, 90), # south vertical\n",
    "    (270, 90), # west vertical\n",
    "]\n",
    "orientations = [0, 90, 180, 270]\n",
    "weather_data = weather.days(irradiances=irradiances, \n",
    "                            wind_orients=orientations, \n",
    "                            heating_base_temperatures=[0, 6, 8 ,10, 12, 14, 16, 18]).dropna(axis=1)\n",
    "weather_data.drop(['icon', 'summary', 'moonPhase', 'windBearing', 'temperatureMaxTime', 'temperatureMinTime',\n",
    "                   'apparentTemperatureMaxTime', 'apparentTemperatureMinTime', 'uvIndexTime', \n",
    "                   'sunsetTime', 'sunriseTime'], \n",
    "                  axis=1, inplace=True)\n",
    "# Add columns for the day-of-week\n",
    "for i, d in zip(range(7), ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']):\n",
    "    weather_data[d] = 0\n",
    "    weather_data.loc[weather_data.index.weekday == i, d] = 1\n",
    "weather_data = weather_data.applymap(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put data together\n",
    "\n",
    "The generator below will return a dataframe with sensor id as first column and all exogenous data as other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(consumable):\n",
    "    dfcons = dfs[consumable]\n",
    "    for sensorid in dfcons.columns:\n",
    "        df = pd.concat([dfcons[sensorid], weather_data], axis=1).dropna()\n",
    "        df = df.tz_convert('Europe/Brussels')\n",
    "        yield sensorid, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = 'gas'\n",
    "analysis_data = data_generator(cons)\n",
    "\n",
    "sensorid, peek = next(analysis_data)\n",
    "peek = peek.resample(rule='MS').sum()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(peek.index, peek[sensorid], '-', color='grey', lw=8, label=cons)\n",
    "for column in peek.columns[1:]:\n",
    "    if 'heatingDegreeDays' in column:\n",
    "        ax2.plot_date(peek.index, peek[column], '-', label=column)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Regression Analysis\n",
    "\n",
    "\n",
    "We run the analysis on monthly and weekly basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = 'electricity' \n",
    "save_figures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = data_generator(cons)\n",
    "\n",
    "mrs_month = []\n",
    "mrs_month_cv = []\n",
    "mrs_week = []\n",
    "for sensorid, data in analysis_data: \n",
    "    data.rename(columns={sensorid:cons}, inplace=True)\n",
    "    \n",
    "    df = data.resample(rule='MS').sum()\n",
    "    if len(df) < 2:\n",
    "        continue\n",
    "    \n",
    "    # monthly model, statistical validation\n",
    "    mrs_month.append(regression.MVLinReg(df.ix[:end_model], cons, p_max=0.03)) \n",
    "    figures = mrs_month[-1].plot(df=df)\n",
    "    \n",
    "    if save_figures:\n",
    "        figures[0].savefig(os.path.join(c.get('data', 'folder'), 'figures', 'multivar_model_'+sensorid+'.png'), dpi=100)\n",
    "        figures[1].savefig(os.path.join(c.get('data', 'folder'), 'figures', 'multivar_results_'+sensorid+'.png'), dpi=100)\n",
    "\n",
    "\n",
    "    # weekly model, statistical validation\n",
    "    df = data.resample(rule='W').sum()\n",
    "    if len(df.ix[:end_model]) < 4:\n",
    "        continue\n",
    "    mrs_week.append(regression.MVLinReg(df.ix[:end_model], cons, p_max=0.02))\n",
    "    if len(df.ix[end_model:]) > 0:\n",
    "        figures = mrs_week[-1].plot(model=False, bar_chart=True, df=df.ix[end_model:])\n",
    "        if save_figures:\n",
    "            figures[0].savefig(os.path.join(c.get('data', 'folder'), 'figures', 'multivar_prediction_weekly_'+sensorid+'.png'), dpi=100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
